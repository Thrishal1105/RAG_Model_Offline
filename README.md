# ðŸ§  Offline RAG Question Answering App


A fully offline **Retrieval-Augmented Generation (RAG)** application that allows users to upload a PDF and ask questions based on its content. This project uses semantic search, vector embeddings, cross-encoder reranking, and a local language model (via Ollama) â€” all without any cloud API dependencies.

![Project Image](https://res.cloudinary.com/dalmvzwgj/image/upload/v1765912453/Screenshot_2025-12-17_002225_rsnhjd.png)
---

## ðŸš€ Project Overview

This application enables you to:

- ðŸ“„ Upload a PDF document
- ðŸ§© Convert it into searchable text chunks
- ðŸ§  Store text embeddings in a vector database
- ðŸ”Ž Retrieve relevant document chunks via semantic search
- ðŸŽ¯ Improve retrieval quality using reranking
- ðŸ¤– Generate detailed answers using a local LLM

---

## ðŸ“¦ Dependencies

### ðŸ›  Tools & Models

These are required before running the project:

 **Ollama** â€” Local language model platform  
 - `llama3.2:1b` â€” for text generation  
 - `nomic-embed-text` â€” for generating context embeddings


